import json
import logging
import os
import shutil
import threading
import time
from datetime import datetime, timedelta
import requests  # Ø§Ø¶Ø§ÙÙ‡ Ø¨Ø±Ø§ÛŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ

# Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ logging Ø¬Ù‡Øª Ø«Ø¨Øª Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(
            "c:\\Developer\\T13_Project\\T13\\data\\self_upgrade.log", encoding="utf-8"
        ),
        logging.StreamHandler(),
    ],
)

VERSION_FILE = "c:\\Developer\\T13_Project\\T13\\data\\version.json"
UPGRADE_LOG_FILE = "c:\\Developer\\T13_Project\\T13\\data\\upgrade_log.json"
BACKUP_DIR = "c:\\Developer\\T13_Project\\T13\\backup\\"


def backup_file(filepath):
    """ÛŒÚ© Ù†Ø³Ø®Ù‡ Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ø§Ø² ÙØ§ÛŒÙ„ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯"""
    try:
        if not os.path.exists(BACKUP_DIR):
            os.makedirs(BACKUP_DIR)
        base = os.path.basename(filepath)
        backup_path = os.path.join(
            BACKUP_DIR, f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{base}"
        )
        shutil.copy(filepath, backup_path)
        logging.info(f"ğŸ’¾ Ù†Ø³Ø®Ù‡ Ù¾Ø´ØªÛŒØ¨Ø§Ù† {backup_path} Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.")
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø³Ø®Ù‡ Ù¾Ø´ØªÛŒØ¨Ø§Ù†: {e}")


def save_version(version, performance_metrics=None):
    record = {
        "version": version,
        "timestamp": datetime.now().isoformat(),
        "performance": performance_metrics or {},
    }
    try:
        backup_file(VERSION_FILE)
        with open(VERSION_FILE, "w", encoding="utf-8") as f:
            json.dump(record, f, ensure_ascii=False, indent=4)
        logging.info("Ù†Ø³Ø®Ù‡ Ø¬Ø¯ÛŒØ¯ Ø³ÛŒØ³ØªÙ… Ø¨Ø§ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ÛŒ Ø«Ø¨Øª Ø´Ø¯.")
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø«Ø¨Øª Ù†Ø³Ø®Ù‡: {e}")


def analyze_for_upgrade(internal_metrics):
    """
    ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª Ø¯Ø§Ø®Ù„ÛŒ Ø³ÛŒØ³ØªÙ… Ø¨Ø±Ø§ÛŒ ØªØ¹ÛŒÛŒÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø±ØªÙ‚Ø§.
    Ø§Ø² Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ù…Ø§Ù†Ù†Ø¯ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ú©Ø¯ØŒ Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø®Ú¯ÙˆÛŒÛŒ Ùˆ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ù†Ø¸Ø§Ø±ØªÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    upgrades = []
    try:
        # Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ ÙØ±Ø¶ÛŒ Ø¯Ø§Ø®Ù„ÛŒ (internal_metrics) Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø´Ø§Ù…Ù„ Ù…ÙˆØ§Ø±Ø¯ÛŒ Ù…Ø«Ù„ "code_complexity"ØŒ "response_time" Ùˆ "error_rate" Ø¨Ø§Ø´Ø¯.
        if internal_metrics.get("code_complexity", 0) > 7:
            upgrades.append("Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø§Ø®ØªØ§Ø± Ú©Ø¯ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ")
        if internal_metrics.get("response_time", 0) > 2:  # Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø®Ú¯ÙˆÛŒÛŒ Ø¨ÛŒØ´ Ø§Ø² 2 Ø«Ø§Ù†ÛŒÙ‡
            upgrades.append("Ø¨Ù‡Ø¨ÙˆØ¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø³ÛŒØ³ØªÙ… Ø¬Ù‡Øª Ú©Ø§Ù‡Ø´ Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø®Ú¯ÙˆÛŒÛŒ")
        if internal_metrics.get("error_rate", 0) > 0.1:  # Ø®Ø·Ø§ Ø¨ÛŒØ´ØªØ± Ø§Ø² 10 Ø¯Ø±ØµØ¯
            upgrades.append("Ø§ÙØ²Ø§ÛŒØ´ Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø¨Ù‡Ø¨ÙˆØ¯ Ú©Ø´Ù Ùˆ Ø§ØµÙ„Ø§Ø­ Ø®Ø·Ø§")
        # Ø­ØªÛŒ Ø§Ú¯Ø± Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ù†Ø±Ù…Ø§Ù„ Ø¨Ø§Ø´Ø¯ØŒ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ú¯ÛŒØ±Ø§Ù†Ù‡ Ø§Ø¹Ù…Ø§Ù„ Ø´ÙˆØ¯.
        upgrades.append("Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø§Ø®ØªØ§Ø± Ú©Ø¯ Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø´Ù Ø®Ø·Ø§")
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª Ø§Ø±ØªÙ‚Ø§: {e}")
    return upgrades


def log_upgrade_suggestion(suggestions):
    record = {"timestamp": datetime.now().isoformat(), "suggestions": suggestions}
    try:
        if not os.path.exists(UPGRADE_LOG_FILE):
            with open(UPGRADE_LOG_FILE, "w", encoding="utf-8") as f:
                json.dump([record], f, ensure_ascii=False, indent=4)
        else:
            with open(UPGRADE_LOG_FILE, "r+", encoding="utf-8") as f:
                try:
                    logs = json.load(f)
                    if not isinstance(logs, list):
                        logs = []
                except json.JSONDecodeError:
                    logs = []
                logs.append(record)
                f.seek(0)
                json.dump(logs, f, ensure_ascii=False, indent=4)
        logging.info("Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø§Ø±ØªÙ‚Ø§ Ø«Ø¨Øª Ø´Ø¯Ù†Ø¯.")
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø«Ø¨Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø§Ø±ØªÙ‚Ø§: {e}")


def auto_refactor():
    try:
        logging.info("ğŸ”„ Ø¢ØºØ§Ø² Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø³ÛŒØ³ØªÙ… (Refactor)...")
        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø³ØªØ§ØªÛŒÚ© Ú©Ø¯ Ùˆ Ø¨Ù‡Ø¨ÙˆØ¯ Ø³Ø§Ø®ØªØ§Ø± Ø¢Ù†
        time.sleep(1)
        # --- Ø§Ø±ØªÙ‚Ø§Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯: ØªØ­Ù„ÛŒÙ„ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø®ÙˆØ¯Ú©Ø§Ø± ---
        # Û±. Ø¨Ø±Ø±Ø³ÛŒ Ø®Ø·ÙˆØ· ØªÚ©Ø±Ø§Ø±ÛŒ Ùˆ Ø­Ø°Ù Ø¢Ù†â€ŒÙ‡Ø§
        with open(__file__, "r", encoding="utf-8") as f:
            code_lines = f.readlines()
        unique_lines = []
        seen = set()
        for line in code_lines:
            if line.strip() not in seen:
                unique_lines.append(line)
                seen.add(line.strip())
        if len(unique_lines) < len(code_lines):
            backup_file(__file__)
            with open(__file__, "w", encoding="utf-8") as f:
                f.writelines(unique_lines)
            logging.info("Ø®Ø·ÙˆØ· ØªÚ©Ø±Ø§Ø±ÛŒ Ø­Ø°Ù Ø´Ø¯Ù†Ø¯ Ùˆ Ú©Ø¯ ØªÙ…ÛŒØ²ØªØ± Ø´Ø¯.")
        # Û². Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ù‡Ø´Ø¯Ø§Ø± Ø®Ø·ÙˆØ· Ø¨Ø³ÛŒØ§Ø± Ø·ÙˆÙ„Ø§Ù†ÛŒ
        long_lines = [i+1 for i, l in enumerate(unique_lines) if len(l) > 120]
        if long_lines:
            logging.warning(f"Ø®Ø·ÙˆØ· Ø¨Ø³ÛŒØ§Ø± Ø·ÙˆÙ„Ø§Ù†ÛŒ (Ø¨ÛŒØ´ Ø§Ø² Û±Û²Û° Ú©Ø§Ø±Ø§Ú©ØªØ±) Ø¯Ø± Ø®Ø·ÙˆØ·: {long_lines}")
        # Û³. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ ØªÙ‚Ø³ÛŒÙ… Ù…Ø§Ú˜ÙˆÙ„ Ø§Ú¯Ø± Ø®Ø·ÙˆØ· Ø²ÛŒØ§Ø¯ Ø¨Ø§Ø´Ø¯
        if len(unique_lines) > 400:
            logging.warning("Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: ØªÙ‚Ø³ÛŒÙ… Ù…Ø§Ú˜ÙˆÙ„ Ø¨Ù‡ Ú†Ù†Ø¯ ÙØ§ÛŒÙ„ Ú©ÙˆÚ†Ú©ØªØ± Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø¨Ù‡ØªØ±.")
        # Û´. Ø«Ø¨Øª snapshot Ø¬Ø¯ÛŒØ¯ Ù¾Ø³ Ø§Ø² refactor
        log_path = os.path.join(os.path.dirname(__file__), "..", "data", "self_upgrade_code_snapshot.log")
        with open(os.path.abspath(log_path), "a", encoding="utf-8") as logf:
            logf.write(f"\n\n===== Refactor Snapshot {datetime.now().isoformat()} =====\n")
            logf.writelines(unique_lines)
        logging.info("âœ… Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø³ÛŒØ³ØªÙ… Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯ Ùˆ snapshot Ø«Ø¨Øª Ø´Ø¯.")
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø³ÛŒØ³ØªÙ…: {e}")


def self_optimize_code():
    """
    Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ: Ø§Ø±ØªÙ‚Ø§ÛŒ Ø®ÙˆØ¯ Ù…Ø§Ú˜ÙˆÙ„ Ø§Ø±ØªÙ‚Ø§ (self-upgrade engine)
    - Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ú¯ Ùˆ Ù†Ø³Ø®Ù‡
    - Ø­Ø°Ù Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ± Ø§Ø² Û³Û° Ø±ÙˆØ²
    - Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ù†Ø³Ø®Ù‡ Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† Ù†Ø³Ø®Ù‡
    - Ø«Ø¨Øª Ú¯Ø²Ø§Ø±Ø´ Ø¨Ù‡Ø¨ÙˆØ¯
    - Ø«Ø¨Øª Ú©Ø¯ Ú©Ø§Ù…Ù„ ÙØ¹Ù„ÛŒ Ù…Ø§Ú˜ÙˆÙ„ Ø¯Ø± Ù„Ø§Ú¯ Ù¾Ø³ Ø§Ø² Ù‡Ø± Ø§Ø±ØªÙ‚Ø§
    """
    try:
        logging.info("ğŸ” Ø´Ø±ÙˆØ¹ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø§Ú˜ÙˆÙ„ Ø§Ø±ØªÙ‚Ø§...")
        # Ø­Ø°Ù Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ± Ø§Ø² Û³Û° Ø±ÙˆØ²
        now = datetime.now()
        removed_logs = 0
        if os.path.exists(BACKUP_DIR):
            for fname in os.listdir(BACKUP_DIR):
                fpath = os.path.join(BACKUP_DIR, fname)
                if os.path.isfile(fpath) and fname.endswith(".json"):
                    try:
                        ts = fname.split('_')[0]
                        file_time = datetime.strptime(ts, "%Y%m%d")
                        if (now - file_time).days > 30:
                            os.remove(fpath)
                            removed_logs += 1
                    except Exception:
                        continue
        # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ù†Ø³Ø®Ù‡ Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† Ù†Ø³Ø®Ù‡
        if os.path.exists(VERSION_FILE):
            backup_file(VERSION_FILE)
        # Ø«Ø¨Øª Ú¯Ø²Ø§Ø±Ø´ Ø¨Ù‡Ø¨ÙˆØ¯
        msg = f"Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ {removed_logs} Ù†Ø³Ø®Ù‡ Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ù‚Ø¯ÛŒÙ…ÛŒ Ùˆ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø¨Ú©Ø§Ù¾ Ù†Ø³Ø®Ù‡ ÙØ¹Ù„ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯."
        logging.info(msg)
        # Ø«Ø¨Øª Ú©Ø¯ Ú©Ø§Ù…Ù„ ÙØ¹Ù„ÛŒ Ù…Ø§Ú˜ÙˆÙ„ Ø¯Ø± Ù„Ø§Ú¯
        with open(__file__, "r", encoding="utf-8") as f:
            code = f.read()
        log_path = os.path.join(os.path.dirname(__file__), "..", "data", "self_upgrade_code_snapshot.log")
        with open(os.path.abspath(log_path), "a", encoding="utf-8") as logf:
            logf.write(f"\n\n===== Snapshot {datetime.now().isoformat()} =====\n")
            logf.write(code)
        logging.info("Ú©Ø¯ Ú©Ø§Ù…Ù„ Ù…Ø§Ú˜ÙˆÙ„ self_upgrade_engine.py Ø¯Ø± Ù„Ø§Ú¯ Ø«Ø¨Øª Ø´Ø¯.")
        return [msg]
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø§Ú˜ÙˆÙ„ Ø§Ø±ØªÙ‚Ø§: {e}")
        return []


def apply_upgrade(suggestions, current_emotion):
    """
    Ø§Ø¹Ù…Ø§Ù„ Ø§Ø±ØªÙ‚Ø§Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ù‡â€ŒØ·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø±ØŒ Ø´Ø§Ù…Ù„ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ… Ùˆ Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ
    """
    try:
        if suggestions:
            logging.info("ğŸš€ Ø¢ØºØ§Ø² Ø§Ø¹Ù…Ø§Ù„ Ø§Ø±ØªÙ‚Ø§Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ...")
            for sug in suggestions:
                logging.info(f"â¤ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¹Ù…Ø§Ù„ ØªØºÛŒÛŒØ±: {sug}")
                # Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ù…Ù†Ø·Ù‚ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¹Ù…Ø§Ù„ Ø§Ø±ØªÙ‚Ø§ (Ù…Ø§Ù†Ù†Ø¯ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ ÛŒØ§ ØªØºÛŒÛŒØ±Ø§Øª Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ú˜ÙˆÙ„) Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯.
                time.sleep(0.5)
            logging.info("âœ… Ø§Ø±ØªÙ‚Ø§Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯Ù†Ø¯.")
        else:
            logging.info("âš™ï¸ Ù‡ÛŒÚ† Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø§Ø±ØªÙ‚Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¹Ù…Ø§Ù„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¹Ù…Ø§Ù„ Ø§Ø±ØªÙ‚Ø§Ù‡Ø§: {e}")


def read_system_emotion_score():
    """
    ØªØ§Ø¨Ø¹ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† ÙˆØ¶Ø¹ÛŒØª Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø³ÛŒØ³ØªÙ….
    Ø¯Ø± Ù…Ø­ÛŒØ· ÙˆØ§Ù‚Ø¹ÛŒ Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¨Ø§ÛŒØ¯ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ… Ø±Ø§ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø®ÙˆØ§Ù†Ø¯.
    """
    # Ù…Ù‚Ø§Ø¯ÛŒØ± Ù†Ù…ÙˆÙ†Ù‡ Ø¬Ù‡Øª Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ
    return {"stress": 8, "hope": 3, "energy": 2}


def ai_analyze_and_rewrite(code, api_url="http://localhost:8000/ai/analyze"):
    """
    Ø§Ø±Ø³Ø§Ù„ Ú©Ø¯ Ø¨Ù‡ Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ ÛŒØ§ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ.
    Ø®Ø±ÙˆØ¬ÛŒ: dict Ø´Ø§Ù…Ù„ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ùˆ (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯) Ú©Ø¯ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒâ€ŒØ´Ø¯Ù‡
    """
    try:
        response = requests.post(api_url, json={"code": code}, timeout=30)
        if response.status_code == 200:
            return response.json()
        else:
            logging.error(f"AI API error: {response.status_code} - {response.text}")
            return {"suggestions": [], "rewritten_code": None}
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ: {e}")
        return {"suggestions": [], "rewritten_code": None}


def self_read_and_suggest(smart_mode=False, ai_api_url="http://localhost:8000/ai/analyze"):
    """
    Ù†Ø³Ø®Ù‡ Ø§Ø±ØªÙ‚Ø§ÛŒØ§ÙØªÙ‡: Ø§Ú¯Ø± smart_mode ÙØ¹Ø§Ù„ Ø¨Ø§Ø´Ø¯ØŒ ØªØ­Ù„ÛŒÙ„ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø§Ø² Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒØ´ÙˆØ¯.
    """
    try:
        with open(__file__, "r", encoding="utf-8") as f:
            code = f.read()
        suggestions = []
        ai_result = None
        long_lines = []  # ØªØ¹Ø±ÛŒÙ long_lines Ù¾ÛŒØ´ Ø§Ø² Ù‡Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡
        if smart_mode:
            ai_result = ai_analyze_and_rewrite(code, ai_api_url)
            suggestions = ai_result.get("suggestions", [])
        else:
            # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: Ø§Ú¯Ø± Ø¯Ø§Ú©â€ŒØ§Ø³ØªØ±ÛŒÙ†Ú¯ ØªÙˆØ§Ø¨Ø¹ Ù†Ø§Ù‚Øµ Ø§Ø³Øª
            if '"""' not in code or code.count('"""') < code.count('def '):
                suggestions.append("Ø¨Ø±Ø±Ø³ÛŒ Ùˆ ØªÚ©Ù…ÛŒÙ„ Ø¯Ø§Ú©â€ŒØ§Ø³ØªØ±ÛŒÙ†Ú¯ ØªÙˆØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ Ø¨Ù‡ØªØ±.")
            if 'except Exception' in code and 'logging.error' not in code:
                suggestions.append("Ø¯Ø± exceptÙ‡Ø§ Ø§Ø² logging.error Ø¨Ø±Ø§ÛŒ Ø«Ø¨Øª Ø®Ø·Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆØ¯.")
            if 'def test_' not in code:
                suggestions.append("Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ ÙˆØ§Ø­Ø¯ Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø¹Ù…Ù„Ú©Ø±Ø¯ ØµØ­ÛŒØ­ Ù…Ø§Ú˜ÙˆÙ„.")
            if 'threading.Thread' in code and 'join' not in code:
                suggestions.append("Ù…Ø¯ÛŒØ±ÛŒØª ØµØ­ÛŒØ­ Ù¾Ø§ÛŒØ§Ù† threadÙ‡Ø§ (graceful shutdown) Ø§Ø¶Ø§ÙÙ‡ Ø´ÙˆØ¯.")
            long_lines = [i+1 for i, l in enumerate(code.splitlines()) if len(l) > 120]
            if long_lines:
                suggestions.append(f"Ú©Ø§Ù‡Ø´ Ø·ÙˆÙ„ Ø®Ø·ÙˆØ· Ø¨Ù„Ù†Ø¯ (Ø¨ÛŒØ´ Ø§Ø² Û±Û²Û° Ú©Ø§Ø±Ø§Ú©ØªØ±) Ø¯Ø± Ø®Ø·ÙˆØ·: {long_lines}")
        # Ø®Ù„Ø§ØµÙ‡ Ø¢Ù…Ø§Ø±ÛŒ Ø³Ø§Ø®ØªØ§Ø± Ú©Ø¯
        stats = None
        try:
            functions_count = code.count('def ')
            lines_count = len(code.splitlines())
            stats = {
                'functions': functions_count,
                'classes': code.count('class '),
                'lines': lines_count,
                'try_blocks': code.count('try:'),
                'except_blocks': code.count('except'),
                'docstrings': code.count('"""'),
                'long_lines': len(long_lines),
            }
        except Exception as e_stats:
            stats = {'error': str(e_stats)}
        # Ø§Ú¯Ø± Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ refactor Ø³Ø§Ø®ØªØ§Ø±ÛŒ Ù„Ø§Ø²Ù… Ø¨ÙˆØ¯ØŒ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
        if (
            isinstance(stats, dict)
            and isinstance(stats.get('functions', 0), int)
            and isinstance(stats.get('lines', 0), int)
            and int(stats.get('functions', 0)) > 10
            and int(stats.get('lines', 0)) > 300
        ):
            suggestions.append("Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: ØªÙ‚Ø³ÛŒÙ… Ù…Ø§Ú˜ÙˆÙ„ Ø¨Ù‡ Ú†Ù†Ø¯ ÙØ§ÛŒÙ„ Ú©ÙˆÚ†Ú©ØªØ± Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ùˆ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø¨Ù‡ØªØ±.")
        # Ø«Ø¨Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ùˆ Ø®Ù„Ø§ØµÙ‡ Ø¯Ø± Ù„Ø§Ú¯
        log_path = os.path.join(os.path.dirname(__file__), "..", "data", "self_upgrade_suggestions.log")
        # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÚ©Ø±Ø§Ø± Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§: ÙÙ‚Ø· Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ù‡Ø´Ø¯Ø§Ø± Ø¨Ø¯Ù‡
        last_suggestions = set()
        meta_path = os.path.join(os.path.dirname(__file__), "..", "data", "self_upgrade_meta.json")
        meta = {'last_run': None, 'run_count': 0, 'last_suggestions': []}
        if os.path.exists(meta_path):
            try:
                with open(meta_path, "r", encoding="utf-8") as mf:
                    meta = json.load(mf)
                    last_suggestions = set(meta.get('last_suggestions', []))
            except Exception:
                pass
        new_suggestions = [s for s in suggestions if s not in last_suggestions]
        with open(os.path.abspath(log_path), "a", encoding="utf-8") as logf:
            logf.write(f"\n\n===== Suggestions {datetime.now().isoformat()} =====\n")
            for s in suggestions:
                logf.write(f"- {s}\n")
            if stats and isinstance(stats, dict) and 'error' in stats:
                logf.write(f"\n[Code Stats Error] {stats['error']}\n")
            else:
                logf.write(f"\n[Code Stats] {stats}\n")
        # Ø§Ú¯Ø± Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…Ù‡Ù… Ø¬Ø¯ÛŒØ¯ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªØŒ Ø¯Ø± Ù„Ø§Ú¯ Ø§ØµÙ„ÛŒ Ù‡Ù… Ù‡Ø´Ø¯Ø§Ø± Ø«Ø¨Øª Ø´ÙˆØ¯
        if new_suggestions:
            logging.warning(f"Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ù…Ù‡Ù… Ø¬Ø¯ÛŒØ¯ Ø®ÙˆØ¯Ú©Ø¯Ø®ÙˆØ§Ù†ÛŒ: {new_suggestions}")
        else:
            logging.info("Ø®ÙˆØ¯Ú©Ø¯Ø®ÙˆØ§Ù†ÛŒ: Ù‡ÛŒÚ† Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…Ù‡Ù… Ø¬Ø¯ÛŒØ¯ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        # Ø«Ø¨Øª Ù…ØªØ§Ø¯ÛŒØªØ§
        meta['last_run'] = datetime.now().isoformat()
        meta['run_count'] = meta.get('run_count', 0) + 1
        meta['last_suggestions'] = suggestions
        with open(meta_path, "w", encoding="utf-8") as mf:
            json.dump(meta, mf, ensure_ascii=False, indent=2)
        return suggestions
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ¯Ú©Ø¯Ø®ÙˆØ§Ù†ÛŒ Ù…Ø§Ú˜ÙˆÙ„ Ø§Ø±ØªÙ‚Ø§: {e}")
        return []


def auto_apply_suggestions(suggestions, rewritten_code=None):
    """
    Ø§Ú¯Ø± Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ù‚Ø§Ø¨Ù„ Ø§Ø¹Ù…Ø§Ù„ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ø§Ø´Ù†Ø¯ (Ù…Ø«Ù„Ø§Ù‹ Ø¯Ø§Ú©â€ŒØ§Ø³ØªØ±ÛŒÙ†Ú¯ ÛŒØ§ ØªÙ‚Ø³ÛŒÙ… Ù…Ø§Ú˜ÙˆÙ„)ØŒ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø¹Ù…Ø§Ù„ Ú©Ù†.
    Ø§Ú¯Ø± Ú©Ø¯ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒâ€ŒØ´Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯ØŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†.
    """
    try:
        applied = []
        if rewritten_code:
            # Ø¨Ú©Ø§Ù¾ Ùˆ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ú©Ø¯
            backup_file(__file__)
            with open(__file__, "w", encoding="utf-8") as f:
                f.write(rewritten_code)
            logging.info("Ú©Ø¯ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒâ€ŒØ´Ø¯Ù‡ ØªÙˆØ³Ø· Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø´Ø¯.")
            applied.append("Ú©Ø¯ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒâ€ŒØ´Ø¯Ù‡ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø´Ø¯.")
        else:
            # Ù†Ù…ÙˆÙ†Ù‡: Ø§ÙØ²ÙˆØ¯Ù† Ø¯Ø§Ú©â€ŒØ§Ø³ØªØ±ÛŒÙ†Ú¯ Ø¨Ù‡ ØªÙˆØ§Ø¨Ø¹ ÙØ§Ù‚Ø¯ Ø¢Ù† (Ù†Ù…ÙˆÙ†Ù‡ Ø³Ø§Ø¯Ù‡)
            if any("Ø¯Ø§Ú©â€ŒØ§Ø³ØªØ±ÛŒÙ†Ú¯" in s for s in suggestions):
                with open(__file__, "r", encoding="utf-8") as f:
                    code = f.read()
                new_code = ""
                for line in code.splitlines():
                    new_code += line + "\n"
                    if line.strip().startswith("def ") and '"""' not in line:
                        new_code += '    """TODO: ØªÙˆØ¶ÛŒØ­ ØªØ§Ø¨Ø¹."""\n'
                backup_file(__file__)
                with open(__file__, "w", encoding="utf-8") as f:
                    f.write(new_code)
                applied.append("Ø¯Ø§Ú©â€ŒØ§Ø³ØªØ±ÛŒÙ†Ú¯ Ø¨Ù‡ ØªÙˆØ§Ø¨Ø¹ ÙØ§Ù‚Ø¯ Ø¢Ù† Ø§ÙØ²ÙˆØ¯Ù‡ Ø´Ø¯.")
        return applied
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¹Ù…Ø§Ù„ Ø®ÙˆØ¯Ú©Ø§Ø± Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª: {e}")
        return []


def upgrade_scheduler(interval_minutes=10, smart_mode=False, ai_api_url="http://localhost:8000/ai/analyze"):
    def scheduled_task():
        while True:
            try:
                next_run = datetime.now() + timedelta(minutes=interval_minutes)
                logging.info(
                    f"â³ Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø± Ø³Ø§Ø¹Øª {next_run.strftime('%H:%M:%S')}"
                )
                time.sleep(interval_minutes * 60)

                logging.info("ğŸš€ Ø¢ØºØ§Ø² Ø¨Ø±Ø±Ø³ÛŒ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ø§Ø±ØªÙ‚Ø§...")
                # Ø®ÙˆØ§Ù†Ø¯Ù† ÙˆØ¶Ø¹ÛŒØª Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ Ø³ÛŒØ³ØªÙ…
                current_emotion = read_system_emotion_score()
                suggestions = analyze_for_upgrade(current_emotion)
                # Ø«Ø¨Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø§Ø±ØªÙ‚Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ Ù„Ø§Ú¯
                if suggestions:
                    log_upgrade_suggestion(suggestions)
                else:
                    logging.info("âœ… Ø³ÛŒØ³ØªÙ… Ù¾Ø§ÛŒØ¯Ø§Ø± Ø§Ø³ØªØ› Ø§Ø±ØªÙ‚Ø§ Ù†ÛŒØ§Ø² Ù†ÛŒØ³Øª.")

                # Ø§Ø¬Ø±Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø§ØµÙ„Ø§Ø­ Ú©Ø¯
                auto_refactor()
                # Ø§Ø¹Ù…Ø§Ù„ Ø§Ø±ØªÙ‚Ø§Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ
                apply_upgrade(suggestions, current_emotion)
                # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ú©Ø¯
                code_suggestions = self_optimize_code()
                if code_suggestions:
                    logging.info("âœ… ØªØºÛŒÛŒØ±Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯Ù†Ø¯.")

                # Ø«Ø¨Øª Ù†Ø³Ø®Ù‡ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…
                save_version("T13.3_V4_Auto", performance_metrics=current_emotion)
                # Ø§Ø¬Ø±Ø§ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± self_read_and_suggest (Ù‡ÙˆØ´Ù…Ù†Ø¯)
                smart_suggestions, rewritten_code = [], None
                try:
                    result = self_read_and_suggest(smart_mode=smart_mode, ai_api_url=ai_api_url)
                    if smart_mode and isinstance(result, tuple):
                        smart_suggestions, rewritten_code = result
                    elif isinstance(result, list):
                        smart_suggestions = result
                except Exception as e:
                    logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø®ÙˆØ¯ØªØ­Ù„ÛŒÙ„â€ŒÚ¯Ø±ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯: {e}")
                # Ø§Ø¹Ù…Ø§Ù„ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ø±Ø®ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª
                if smart_suggestions or rewritten_code:
                    auto_apply_suggestions(smart_suggestions, rewritten_code)
            except Exception as e:
                logging.error(f"Ø®Ø·Ø§ Ø¯Ø± ÙˆØ¸ÛŒÙÙ‡ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø±ØªÙ‚Ø§: {e}")
                time.sleep(5)

    threading.Thread(target=scheduled_task, daemon=True).start()
    logging.info("ğŸ•’ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø±ØªÙ‚Ø§ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯.")


if __name__ == "__main__":
    upgrade_scheduler(interval_minutes=1, smart_mode=True)
    # Ù†Ú¯Ù‡â€ŒØ¯Ø§Ø±ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ ÙØ¹Ø§Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ
    while True:
        time.sleep(1)
